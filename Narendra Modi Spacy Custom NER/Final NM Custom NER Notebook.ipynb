{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps involved :- \n",
    "1. Loading Training/Testing Data\n",
    "2. Formatting into structured JSON format\n",
    "3. Saving File named \"\" \"updated\" + Filename \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading JSON Library\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"f.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename,\"r\", encoding=\"utf8\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savetoJSONFormat(data):\n",
    "    index = data.find(\"\\n\")\n",
    "    data[:index+2]\n",
    "    \n",
    "    # no \",\" after every sentence and overall [] are missing for proper json input\n",
    "    datareplaced = data.replace(\"\\n\",\",\")\n",
    "    datareplaced.find(\"\\n\")\n",
    "    \n",
    "    #above code add \",\" at last sentence so removing it\n",
    "    index = len(datareplaced)\n",
    "    datareplaced = datareplaced[:index-1]\n",
    "    \n",
    "    \n",
    "    with open(\"updated \"+filename,\"w+\") as f:\n",
    "        f.write(\"[\" + datareplaced + \"]\")\n",
    "        print(\"File saved :- \", \"updated \"+filename)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved :-  updated f.json\n"
     ]
    }
   ],
   "source": [
    "savetoJSONFormat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps invloved :-\n",
    "1. Loading JSON File of  Traning and Testing Data\n",
    "2. Formating JSON file to required format for training\n",
    "\n",
    "{ Loading the New Testing Set (Using On Unseen Data Set)  to avoid overfitting of the training data }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile = \"f.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"updated \"+trainfile) as train_data:\n",
    "    train = json.load(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gujarmal Modi 9 August 1902  22 January 1976 was an Indian industrialist and philanthropist, who co-established the Modi Group of companies and the industrial city of Modinagar in 1933, along with his brother Kedar Nath Modi', {'entities': [(0, 13, 'Person'), (209, 224, 'Person'), (167, 176, 'Location')]})\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = []\n",
    "\n",
    "for data in train:\n",
    "    ents = [tuple(entity) for entity in data['labels']]\n",
    "    TRAIN_DATA.append((data['text'],{'entities':ents}))\n",
    "\n",
    "print(TRAIN_DATA[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile =  \"train1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"updated \"+testfile) as test_data:\n",
    "    test = json.load(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PM Modi and his officials will be holding talks and inaugurate a few defence projects', {'entities': [(0, 7, 'Narendra Modi')]})\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA = []\n",
    "\n",
    "for data in test:\n",
    "    ents = [tuple(entity) for entity in data['labels']]\n",
    "    TEST_DATA.append((data['text'],{'entities':ents}))\n",
    "    \n",
    "print(TEST_DATA[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part  3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps involved :- \n",
    "1. Loading required library\n",
    "2. Setting up the parameters for traning\n",
    "3. Traning and saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random # random function for to remove bais in Traning Data\n",
    "\n",
    "# for batch parsing \n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# For evaluateing the model from testing set\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spacy(TRAIN_DATA,TEST_DATA,iterations,droprate = 0.5,modelName = \"modelTrained\"):\n",
    "    \n",
    "    \n",
    "    modiner = spacy.blank('en')  # create blank Language class\n",
    "    \n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in modiner.pipe_names:\n",
    "        ner = modiner.create_pipe('ner')\n",
    "        modiner.add_pipe(ner, last=True)\n",
    "     \n",
    "    # setting up f1score\n",
    "    f1score = 0.0000\n",
    "\n",
    "    \n",
    "    # add labels that will be involved in training \n",
    "    for _, annotations in TRAIN_DATA:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in modiner.pipe_names if pipe != 'ner']\n",
    "    with modiner.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = modiner.begin_training()\n",
    "        \n",
    "        # --Iterations Starts--\n",
    "        for itn in range(iterations):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            #--Shuffling Traning Data--\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            \n",
    "                      \n",
    "                    \n",
    "            # batch Traning For better Training and Learning of model\n",
    "            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                modiner.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=droprate,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "            print(losses)\n",
    "            \n",
    "            \n",
    "            # Evaluating the Current Model Score \n",
    "            results = evaluate(modiner, TEST_DATA)\n",
    "            print(\"Current Score :-\",results[\"ents_f\"], \"Precision  :-\",results[\"ents_p\"], \"Recall  :-\",results[\"ents_r\"])\n",
    "#             print(\"Precision  :-\",results[\"ents_p\"])\n",
    "#             print(\"Recall  :-\",results[\"ents_r\"])\n",
    "\n",
    "            \n",
    "            # loading previous best saved model in start of traning \n",
    "            if f1score == 0.00:\n",
    "                try:                    \n",
    "                    pnlp = spacy.load(modelName)\n",
    "                    result = evaluate(pnlp, TEST_DATA) # calling evaluate function \n",
    "                    f1score = result[\"ents_f\"]\n",
    "                except:\n",
    "                    print(\"Previous Model not found\")\n",
    "                    \n",
    "            print(\"Best Sccore :- \",f1score)\n",
    "            print(\"------------------------------------\")\n",
    "            # finding out the best score\n",
    "            if f1score < results[\"ents_f\"]:\n",
    "                f1score = results[\"ents_f\"]\n",
    "                # Save our trained Model if the score if grater than best score else no change in previous model\n",
    "                modiner.to_disk(modelName)\n",
    "                \n",
    "    print(\"-----Best Model is Saved-----\")\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ner_model, examples):\n",
    "    scorer = Scorer()\n",
    "     \n",
    "    #loading tags for each input and Evaluating them\n",
    "    for input_, annotations in examples:\n",
    "        tags = []\n",
    "        # loading text\n",
    "        doc_gold_text = ner_model.make_doc(input_)\n",
    "        \n",
    "        #loading all tags for that text\n",
    "        for ent in annotations.get('entities'):\n",
    "            tags.append(ent)\n",
    "            \n",
    "        # Evaluating the tags    \n",
    "        gold = GoldParse(doc_gold_text, entities=tags)\n",
    "        pred_value = ner_model(input_)\n",
    "        scorer.score(pred_value, gold)\n",
    "        \n",
    "        \n",
    "    return scorer.scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNERModel(modelName = \"modelTrained\"):\n",
    "    pnlp = spacy.load(modelName)\n",
    "    return pnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(model,TEST_DATA):\n",
    "    result = evaluate(model, TEST_DATA) # calling evaluate function \n",
    "    f1score = result[\"ents_f\"]\n",
    "    precision = result[\"ents_p\"]\n",
    "    recall = result[\"ents_r\"]\n",
    "    print(\"F1 score of Model is :-\",f1score)\n",
    "    print(\"Precision of Model is :-\",precision)\n",
    "    print(\"Recall of Model is :-\",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traning the model with 50 iterations\n",
    "train_spacy(TRAIN_DATA,TEST_DATA, 100,droprate = 0.55, modelName = \"nm2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading the saved model\n",
    "pnlp = loadNERModel(\"nm2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the score of the model\n",
    "f1score(pnlp,TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testcase = pnlp(TEST_DATA[0][0])\n",
    "displacy.render(testcase, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,30):\n",
    "    try:        \n",
    "        testcase = pnlp(TEST_DATA[i][0])\n",
    "        displacy.render(testcase, style='ent', jupyter=True)\n",
    "        print(\"--\")\n",
    "    except:\n",
    "        a=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainstring = TRAIN_DATA[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    testcase = pnlp(TRAIN_DATA[i][0])\n",
    "    displacy.render(testcase, style='ent', jupyter=True)\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
