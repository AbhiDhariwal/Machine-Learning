{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " CRNN - cropped text image to text Handwriting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1w0Su46qsAsLMaVbDtrQ0xRu_lLDZs-mV",
      "authorship_tag": "ABX9TyMZh4cPPnEPxpdCrKtUYh/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhiDhariwal/Machine-Learning/blob/master/CRNN_cropped_text_image_to_text_Handwriting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP5oGrGwENNy"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\"\n",
        ")\n",
        "%matplotlib inline\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import build_montages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import keras\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "import pickle\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils.contours import sort_contours\n",
        "import imutils\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout,Concatenate\n",
        "from keras.optimizers import Adam\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ1bnTF0SNQI"
      },
      "source": [
        "# cd /content/drive/My Drive/ocr_dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MG7LfOSSNSI"
      },
      "source": [
        "# cp rethink_ux_text.zip /content/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShRadTEZSNWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b3ff4c-2156-41e9-c486-5bf674e3ad17"
      },
      "source": [
        "cd /content/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V13pDntYSkzX"
      },
      "source": [
        "# %%capture\n",
        "# !unzip rethink_ux_text.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgbJ0s4CUqOL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def savePaddedImg(img):\n",
        "    #create empty matrix\n",
        "    vis = 255-np.zeros((45, 280), np.uint8)\n",
        "    try:\n",
        "        h1,w1 = img.shape\n",
        "    except:\n",
        "        h1,w1 = 0,0\n",
        "    #combine  image over blank img\n",
        "    vis[:h1, :w1] = img\n",
        "    return vis/255\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyduMmsZWCzK"
      },
      "source": [
        "def savePaddedImg1(img):\n",
        "    #create empty matrix\n",
        "    vis = 255-np.zeros((45, 280), np.uint8)\n",
        "    try:\n",
        "        h1,w1 = img.shape\n",
        "    except:\n",
        "        h1,w1 = 0,0\n",
        "    #combine  image over blank img\n",
        "    vis[:h1, :w1] = img\n",
        "    return vis\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDN5JrOUSsZY"
      },
      "source": [
        "def load_rethink_image(img):\n",
        "    tup = img.shape\n",
        "    yy = tup[0]\n",
        "    xx = tup[1]\n",
        "    \n",
        "    # print(tup)\n",
        "    ## reconfiguring image to remove unneccessary item\n",
        "    if xx == 388:\n",
        "        # print(\"--\")\n",
        "        if yy<=27:\n",
        "            img = img[:,-320:-40]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:,-311:])\n",
        "        elif yy>27 and yy<=30:\n",
        "            img = img[:-1,-320:-40]\n",
        "           \n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:yy-2,-312:])\n",
        "        elif yy>31 and yy<=35:\n",
        "            img= img[:30,-320:-40]\n",
        "            # cv2_imshow(img)\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:29,-312:])\n",
        "        elif yy==36:\n",
        "            img = img[8:,-320:-40]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[10:,-312:])\n",
        "        elif yy==31:\n",
        "            img = img[:,-320:-40]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:-2,-312:])\n",
        "        #above 60y crop and 30 at beign\n",
        "    elif xx>=250 and xx<286: \n",
        "        # print(\"<>\")\n",
        "        if yy == 31:\n",
        "            img= img[2:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[3:-1,:])\n",
        "        elif yy>=32 and yy<=37:\n",
        "            img = img[-35:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-33:60,:])\n",
        "        elif yy == 38:\n",
        "            img = img[33:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[33:,:])\n",
        "        elif yy>=39 and yy<50:\n",
        "            img = img[-30:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-28:,:])\n",
        "        elif yy == 50:\n",
        "            img = img[-30:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-26:,:])\n",
        "        elif yy >= 51 and yy<=59:\n",
        "            img = img[-26:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-26:,:])\n",
        "        elif yy>=60:\n",
        "            img = img[-36:65,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-33:60,:])\n",
        "    elif xx == 324:\n",
        "        # print(\"{}\")\n",
        "        if yy==44:\n",
        "            img = img[:,:-50]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[5:-5,:])\n",
        "        else:\n",
        "            img = img[:,:-50]\n",
        "    # print(img.shape)\n",
        "    return img\n",
        "\n",
        "   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhFMq9O8SsRD"
      },
      "source": [
        "def load_rethink_image(img):\n",
        "    tup = img.shape\n",
        "    yy = tup[0]\n",
        "    xx = tup[1]\n",
        "    \n",
        "    # print(tup)\n",
        "    ## reconfiguring image to remove unneccessary item\n",
        "    if xx == 388:\n",
        "        # print(\"--\")\n",
        "        if yy<=27:\n",
        "            img = img[:,-320:-40]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:,-311:])\n",
        "        elif yy>27 and yy<=30:\n",
        "            img = img[:-1,-320:-40]\n",
        "           \n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:yy-2,-312:])\n",
        "        elif yy>31 and yy<=35:\n",
        "            img= img[:31,-320:-40]\n",
        "            # cv2_imshow(img)\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:29,-312:])\n",
        "        elif yy==36:\n",
        "            img = img[8:,-320:-40]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[10:,-312:])\n",
        "        elif yy==31:\n",
        "            img = img[:,-320:-40]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:-2,-312:])\n",
        "        #above 60y crop and 30 at beign\n",
        "    elif xx>=250 and xx<286: \n",
        "        # print(\"<>\")\n",
        "        if yy == 31:\n",
        "            img= img[:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[3:-1,:])\n",
        "        elif yy>=32 and yy<=34:\n",
        "            img = img[2:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-33:60,:])\n",
        "        elif yy>=35 and yy<=37:\n",
        "            img = img[-35:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-33:60,:])\n",
        "        elif yy == 38:\n",
        "            img = img[30:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[33:,:])\n",
        "        elif yy>=39 and yy<50:\n",
        "            img = img[-30:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-28:,:])\n",
        "        elif yy == 50:\n",
        "            img = img[-30:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-26:,:])\n",
        "        elif yy >= 51 and yy<=59:\n",
        "            img = img[-30:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-26:,:])\n",
        "        elif yy>=60:\n",
        "            img = img[-38:70,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-33:60,:])\n",
        "    elif xx == 324:\n",
        "        # print(\"{}\")\n",
        "        if yy==44:\n",
        "            img = img[:,:-50]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[5:-5,:])\n",
        "        else:\n",
        "            img = img[:,:-50]\n",
        "    # print(img.shape)\n",
        "    return img\n",
        "\n",
        "   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iruWSlk5DEfb"
      },
      "source": [
        "def load_rethink_image(img):\n",
        "    tup = img.shape\n",
        "    yy = tup[0]\n",
        "    xx = tup[1]\n",
        "    \n",
        "    # print(tup)\n",
        "    ## reconfiguring image to remove unneccessary item\n",
        "    if xx == 388:\n",
        "        # print(\"--\")\n",
        "        if yy<=27:\n",
        "            img = img[:,-320:-40]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:,-311:])\n",
        "        elif yy>27 and yy<=30:\n",
        "            img = img[:-1,-320:-40]\n",
        "           \n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:yy-2,-312:])\n",
        "        elif yy>31 and yy<=35:\n",
        "            img= img[:31,-320:-40]\n",
        "            # cv2_imshow(img)\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:29,-312:])\n",
        "        elif yy==36:\n",
        "            img = img[8:,-320:-40]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[10:,-312:])\n",
        "        elif yy==31:\n",
        "            img = img[:,-320:-40]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[:-2,-312:])\n",
        "        #above 60y crop and 30 at beign\n",
        "    elif xx>=250 and xx<286: \n",
        "        # print(\"<>\")\n",
        "        if yy == 31:\n",
        "            img= img[:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[3:-1,:])\n",
        "        elif yy>=32 and yy<=34:\n",
        "            img = img[:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-33:60,:])\n",
        "        elif yy>=35 and yy<=37:\n",
        "            img = img[:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-33:60,:])\n",
        "        elif yy == 38:\n",
        "            img = img[:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[33:,:])\n",
        "        elif yy>=39 and yy<50:\n",
        "            img = img[-45:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-28:,:])\n",
        "        elif yy == 50:\n",
        "            img = img[10:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-26:,:])\n",
        "        elif yy >= 51 and yy<=59:\n",
        "            img = img[-45:,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-26:,:])\n",
        "        elif yy>=60:\n",
        "            img = img[25:70,:280]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[-33:60,:])\n",
        "    elif xx == 324:\n",
        "        # print(\"{}\")\n",
        "        if yy==44:\n",
        "            img = img[:,:-50]\n",
        "            # cv2.imwrite(processed_path+\"/\" + img_name,img[5:-5,:])\n",
        "        else:\n",
        "            img = img[:,:-50]\n",
        "    # print(img.shape)\n",
        "    return img\n",
        "\n",
        "   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVh2z6VKJ0TR"
      },
      "source": [
        "\n",
        "def save_obj(obj, name ):\n",
        "    with open(name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "    f.close()\n",
        "\n",
        "def load_obj(name ):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        val = pickle.load(f)\n",
        "    f.close()\n",
        "    return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Q9fyt7WrNV"
      },
      "source": [
        "\n",
        "alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\n",
        "max_str_len = 25 # max length of input labels\n",
        "num_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\n",
        "num_of_timestamps = 35 # max length of predicted labels\n",
        "\n",
        "\n",
        "def label_to_num(label):\n",
        "    label_num = []\n",
        "    for ch in label:\n",
        "        label_num.append(alphabets.find(ch))\n",
        "        \n",
        "    return np.array(label_num)\n",
        "\n",
        "def num_to_label(num):\n",
        "    ret = \"\"\n",
        "    for ch in num:\n",
        "        if ch == -1:  # CTC Blank\n",
        "            break\n",
        "        else:\n",
        "            ret+=alphabets[ch]\n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahOLHStj-GTA"
      },
      "source": [
        "def load_train_test_set(train_,test_):\n",
        "    train_x = []\n",
        "    train_y = []\n",
        "    test_x = []\n",
        "    test_y = []\n",
        "    folder = \"TRAIN/\"\n",
        "\n",
        "    for i in tqdm(train_):\n",
        "        train_x.append(savePaddedImg(load_rethink_image( cv2.imread(folder+imglist[i], cv2.IMREAD_GRAYSCALE))))\n",
        "        train_y.append(values[i])\n",
        "\n",
        "    for k in tqdm(test_):\n",
        "        test_x.append(savePaddedImg(load_rethink_image( cv2.imread(folder+imglist[k], cv2.IMREAD_GRAYSCALE))))\n",
        "        test_y.append(values[k])\n",
        "\n",
        "    return train_x,train_y,test_x,test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsAs-Qx5Y3PP"
      },
      "source": [
        "\n",
        "folder = \"TRAIN/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sfos-oR0Fd4"
      },
      "source": [
        "### load train set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaHjvch5UTZf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "ed5cb986-92fa-4201-b6d9-a315f6498d58"
      },
      "source": [
        "df = pd.read_csv(\"TRAIN.csv\")\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FILENAME</th>\n",
              "      <th>VALUES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000.jpg</td>\n",
              "      <td>KESSELER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>LUCAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>ELYN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>ALONZO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>NINO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     FILENAME    VALUES\n",
              "0  000000.jpg  KESSELER\n",
              "1  000001.jpg     LUCAS\n",
              "2  000002.jpg      ELYN\n",
              "3  000003.jpg    ALONZO\n",
              "4  000004.jpg      NINO"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abphNBSZ3AMe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GDazv-51-P0"
      },
      "source": [
        "isna = df.VALUES.isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAayHu9O2HFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e5ccba-4e56-4e21-bbd5-9da07ff2260c"
      },
      "source": [
        "for ind in range(len(isna)):\n",
        "    if isna[ind] == True:\n",
        "        df.iloc[ind].VALUES = \" \"\n",
        "        print(ind)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39\n",
            "415\n",
            "3551\n",
            "3555\n",
            "3730\n",
            "4226\n",
            "4576\n",
            "6970\n",
            "7477\n",
            "8538\n",
            "8814\n",
            "8911\n",
            "9382\n",
            "9449\n",
            "9613\n",
            "10105\n",
            "11012\n",
            "11728\n",
            "11813\n",
            "12105\n",
            "14236\n",
            "14606\n",
            "14860\n",
            "15530\n",
            "16266\n",
            "16625\n",
            "16769\n",
            "16991\n",
            "17490\n",
            "17682\n",
            "17707\n",
            "18196\n",
            "18198\n",
            "18511\n",
            "18562\n",
            "18889\n",
            "19027\n",
            "19551\n",
            "19942\n",
            "20070\n",
            "20262\n",
            "20403\n",
            "21062\n",
            "21223\n",
            "21289\n",
            "21652\n",
            "24541\n",
            "24920\n",
            "25226\n",
            "25710\n",
            "26021\n",
            "26169\n",
            "26410\n",
            "26710\n",
            "26748\n",
            "27586\n",
            "29604\n",
            "29750\n",
            "30506\n",
            "31776\n",
            "32402\n",
            "32568\n",
            "32644\n",
            "32740\n",
            "32861\n",
            "33074\n",
            "34050\n",
            "34135\n",
            "34627\n",
            "35424\n",
            "36637\n",
            "37227\n",
            "38362\n",
            "39147\n",
            "39193\n",
            "39638\n",
            "39998\n",
            "40506\n",
            "40796\n",
            "40826\n",
            "40869\n",
            "40905\n",
            "41146\n",
            "41550\n",
            "41890\n",
            "42623\n",
            "43406\n",
            "43889\n",
            "46801\n",
            "46953\n",
            "47096\n",
            "47441\n",
            "47529\n",
            "47726\n",
            "47858\n",
            "48357\n",
            "49333\n",
            "51943\n",
            "53158\n",
            "53253\n",
            "53907\n",
            "54118\n",
            "54161\n",
            "54859\n",
            "56666\n",
            "57584\n",
            "57953\n",
            "59938\n",
            "64438\n",
            "64642\n",
            "65202\n",
            "65464\n",
            "66283\n",
            "66378\n",
            "66446\n",
            "66474\n",
            "67508\n",
            "67652\n",
            "69262\n",
            "69588\n",
            "70872\n",
            "71838\n",
            "73378\n",
            "74007\n",
            "74461\n",
            "75927\n",
            "76441\n",
            "76530\n",
            "76775\n",
            "77139\n",
            "79638\n",
            "80290\n",
            "82202\n",
            "82532\n",
            "82628\n",
            "84988\n",
            "85303\n",
            "85748\n",
            "86357\n",
            "86462\n",
            "86476\n",
            "86600\n",
            "87032\n",
            "87987\n",
            "88211\n",
            "90000\n",
            "91075\n",
            "91262\n",
            "91350\n",
            "91426\n",
            "92542\n",
            "93354\n",
            "94813\n",
            "94897\n",
            "94927\n",
            "95116\n",
            "95133\n",
            "95739\n",
            "95816\n",
            "96245\n",
            "96560\n",
            "97251\n",
            "97510\n",
            "97887\n",
            "99008\n",
            "99141\n",
            "99576\n",
            "99693\n",
            "100892\n",
            "100913\n",
            "101318\n",
            "101386\n",
            "103622\n",
            "103725\n",
            "104353\n",
            "104493\n",
            "104758\n",
            "104881\n",
            "105818\n",
            "106329\n",
            "106365\n",
            "106386\n",
            "107340\n",
            "109085\n",
            "109465\n",
            "109728\n",
            "109759\n",
            "110787\n",
            "110985\n",
            "111084\n",
            "111584\n",
            "111789\n",
            "112091\n",
            "113503\n",
            "114681\n",
            "115506\n",
            "116360\n",
            "117151\n",
            "117937\n",
            "118229\n",
            "118565\n",
            "120179\n",
            "120968\n",
            "121019\n",
            "121241\n",
            "122217\n",
            "122514\n",
            "123457\n",
            "124449\n",
            "125302\n",
            "125647\n",
            "127262\n",
            "127787\n",
            "130479\n",
            "130584\n",
            "130724\n",
            "131029\n",
            "131261\n",
            "131921\n",
            "132685\n",
            "133052\n",
            "134412\n",
            "134515\n",
            "135066\n",
            "136772\n",
            "137055\n",
            "138478\n",
            "141614\n",
            "141696\n",
            "141747\n",
            "142514\n",
            "143570\n",
            "143853\n",
            "144997\n",
            "145138\n",
            "145347\n",
            "148481\n",
            "148786\n",
            "148821\n",
            "149288\n",
            "150017\n",
            "150937\n",
            "150967\n",
            "151753\n",
            "153151\n",
            "153170\n",
            "153223\n",
            "153468\n",
            "153638\n",
            "153862\n",
            "154274\n",
            "154469\n",
            "154567\n",
            "154681\n",
            "155385\n",
            "155600\n",
            "155737\n",
            "156150\n",
            "156360\n",
            "157201\n",
            "157406\n",
            "157507\n",
            "157755\n",
            "157980\n",
            "158901\n",
            "159773\n",
            "159932\n",
            "161658\n",
            "161918\n",
            "162151\n",
            "164285\n",
            "165176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSyvB0hy2fTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e6e851-6335-4644-dab9-afaf6b98fda5"
      },
      "source": [
        "df.iloc[39]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FILENAME    000039.jpg\n",
              "VALUES                \n",
              "Name: 39, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHbqBXVAkqKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbb7826-5634-48f7-c4e7-6b9364478b32"
      },
      "source": [
        "print(len(df))\n",
        "df = df.dropna()\n",
        "\n",
        "values = df.VALUES\n",
        "imglist = df.FILENAME\n",
        "print(len(df))\n",
        "imglist[:5]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "165480\n",
            "165480\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    000000.jpg\n",
              "1    000001.jpg\n",
              "2    000002.jpg\n",
              "3    000003.jpg\n",
              "4    000004.jpg\n",
              "Name: FILENAME, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx5larL5lahv"
      },
      "source": [
        "# df.reset_index(inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hux65Vq-bxE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05444831-f80b-4918-be8a-3c5558f95d63"
      },
      "source": [
        "len(imglist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "165480"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJbhe639-5Pj"
      },
      "source": [
        "import pickle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAtm1d_ueDFB"
      },
      "source": [
        "max_str_len = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFsDfGATZSrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34c41d1-fd66-4e38-c834-241ef79e2d63"
      },
      "source": [
        "import gc \n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svtA7wlOgdfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd75248-ffc4-4058-8f4d-c50fdca45f7e"
      },
      "source": [
        "\n",
        "input_data = Input(shape=(45, 280, 1), name='input')\n",
        "\n",
        "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \n",
        "inner = BatchNormalization()(inner)\n",
        "inner = Activation('relu')(inner)\n",
        "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
        "\n",
        "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
        "inner = BatchNormalization()(inner)\n",
        "inner = Activation('relu')(inner)\n",
        "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
        "inner = Dropout(0.3)(inner)\n",
        "\n",
        "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
        "inner = BatchNormalization()(inner)\n",
        "inner = Activation('relu')(inner)\n",
        "inner = MaxPooling2D(pool_size=(2, 2), name='max3')(inner)\n",
        "inner = Dropout(0.3)(inner)\n",
        "\n",
        "inner = Conv2D(128, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)\n",
        "inner = BatchNormalization()(inner)\n",
        "inner = Activation('relu')(inner)\n",
        "inner = MaxPooling2D(pool_size=(2, 1), name='max4')(inner)\n",
        "inner = Dropout(0.3)(inner)\n",
        "\n",
        "# CNN to RNN\n",
        "inner = Reshape(target_shape=((35, 256)), name='reshape')(inner)\n",
        "inner = Dense(70, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
        "\n",
        "## RNN\n",
        "inner = Bidirectional(LSTM(64, return_sequences=True), name = 'lstm1')(inner)\n",
        "inner = Bidirectional(LSTM(64, return_sequences=True), name = 'lstm2')(inner)\n",
        "\n",
        "## OUTPUT\n",
        "\n",
        "inner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\n",
        "y_pred = Activation('softmax', name='softmax')(inner)\n",
        "\n",
        "model = Model(inputs=input_data, outputs=y_pred)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 45, 280, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 45, 280, 32)       320       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 45, 280, 32)       128       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 45, 280, 32)       0         \n",
            "_________________________________________________________________\n",
            "max1 (MaxPooling2D)          (None, 22, 140, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 22, 140, 64)       18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 22, 140, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 22, 140, 64)       0         \n",
            "_________________________________________________________________\n",
            "max2 (MaxPooling2D)          (None, 11, 70, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 11, 70, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 11, 70, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 11, 70, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 11, 70, 128)       0         \n",
            "_________________________________________________________________\n",
            "max3 (MaxPooling2D)          (None, 5, 35, 128)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 35, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 5, 35, 128)        147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 5, 35, 128)        512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 5, 35, 128)        0         \n",
            "_________________________________________________________________\n",
            "max4 (MaxPooling2D)          (None, 2, 35, 128)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 35, 128)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 35, 256)           0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 35, 70)            17990     \n",
            "_________________________________________________________________\n",
            "lstm1 (Bidirectional)        (None, 35, 128)           69120     \n",
            "_________________________________________________________________\n",
            "lstm2 (Bidirectional)        (None, 35, 128)           98816     \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 35, 30)            3870      \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 35, 30)            0         \n",
            "=================================================================\n",
            "Total params: 431,460\n",
            "Trainable params: 430,756\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIuIGA90Q_8x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHbiUMWhFy9c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N_j_wolUK7g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9NiRe0fg5KP"
      },
      "source": [
        "\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    # the 2 is critical here since the first couple outputs of the RNN\n",
        "    # tend to be garbage\n",
        "    y_pred = y_pred[:, :, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAet7NrghEnu"
      },
      "source": [
        "\n",
        "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='int8')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int8')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int8')\n",
        "\n",
        "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
        "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JS4fBf9r-wU"
      },
      "source": [
        "\n",
        "# the loss calculation occurs elsewhere, so we use a dummy lambda function for the loss\n",
        "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr = 0.0001))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzLDCxpaJdLu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0YUOjBHgsYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c745fcc-d9c6-4cc7-c740-aafcee061aa9"
      },
      "source": [
        "import gc \n",
        "gc.collect()\n",
        "\n",
        "countxx = 0\n",
        "indexes = list(range(len(df)))\n",
        "kf = KFold(n_splits=3)\n",
        "# as dataset is large we can load in set of 50k img\n",
        "for train_index, test_index in kf.split(indexes):\n",
        "    kf1 = KFold(n_splits=3)\n",
        "    # then we further split into 2:1 ratio so we do not overfit \n",
        "    for train_, test_ in kf1.split(test_index):\n",
        "        train_y = np.array([])\n",
        "        valid_y = np.array([])\n",
        "        tx, ty,tesx,tesy = load_train_test_set(train_,test_)\n",
        "        countxx += 1\n",
        "        # save_obj(imgset,\"/content/drive/My Drive/ocr_dataset/ux_text_dataset_set\" + str(countxx) )\n",
        "        print(countxx,\":- TRAIN:\", len(train_), \"TEST:\", len(test_))\n",
        "        \n",
        "        tx = np.array(tx).reshape(-1, 45, 280, 1)\n",
        "        tesx = np.array(tesx).reshape(-1, 45, 280, 1)\n",
        "        train_size = len(ty)\n",
        "        val_size = len(tesy)\n",
        "\n",
        "        train_y = np.ones([train_size, max_str_len]) * -1\n",
        "        train_label_len = np.zeros([train_size, 1])\n",
        "        train_input_len = np.ones([train_size, 1]) * (num_of_timestamps)\n",
        "        train_output = np.zeros([train_size])\n",
        "\n",
        "        for i in range(train_size):\n",
        "            string = ty[i].upper()\n",
        "            train_label_len[i] = len(string)\n",
        "            train_y[i, 0:len(string)]= label_to_num(string)\n",
        "\n",
        "        valid_y = np.ones([val_size, max_str_len]) * -1\n",
        "        valid_label_len = np.zeros([val_size, 1])\n",
        "        valid_input_len = np.ones([val_size, 1]) * (num_of_timestamps)\n",
        "        valid_output = np.zeros([val_size])\n",
        "\n",
        "        for i in range(val_size):\n",
        "            string = tesy[i].upper()\n",
        "            valid_label_len[i] = len(string)\n",
        "            valid_y[i, 0:len(string)]= label_to_num(string) \n",
        "\n",
        "        filepath = \"/content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold\" + str(countxx) + \"_{val_loss:.3f}.h5\"\n",
        "\n",
        "        # del imgset\n",
        "\n",
        "        MC = keras.callbacks.ModelCheckpoint(\n",
        "            filepath,\n",
        "            monitor=\"val_loss\",\n",
        "            verbose=1,\n",
        "            save_best_only=True,\n",
        "            mode=\"auto\",\n",
        "            save_freq=\"epoch\",\n",
        "        )\n",
        "\n",
        "        model_final.fit(x=[tx, train_y, train_input_len, train_label_len], y=train_output, \n",
        "                        validation_data=([tesx, valid_y, valid_input_len, valid_label_len], valid_output),callbacks=[MC],\n",
        "                        epochs=300, batch_size=128)\n",
        "        \n",
        "        # import gc \n",
        "        gc.collect()\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "288/288 [==============================] - ETA: 0s - loss: 6.2568\n",
            "Epoch 00006: val_loss improved from 6.07142 to 5.56634, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_5.566.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 6.2568 - val_loss: 5.5663\n",
            "Epoch 7/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 5.7087\n",
            "Epoch 00007: val_loss improved from 5.56634 to 5.05535, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_5.055.h5\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 5.7087 - val_loss: 5.0554\n",
            "Epoch 8/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 5.3025\n",
            "Epoch 00008: val_loss improved from 5.05535 to 4.90282, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_4.903.h5\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 5.3025 - val_loss: 4.9028\n",
            "Epoch 9/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 4.9736\n",
            "Epoch 00009: val_loss improved from 4.90282 to 4.86365, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_4.864.h5\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 4.9736 - val_loss: 4.8636\n",
            "Epoch 10/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 4.6868\n",
            "Epoch 00010: val_loss did not improve from 4.86365\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 4.6868 - val_loss: 4.9024\n",
            "Epoch 11/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 4.4567\n",
            "Epoch 00011: val_loss improved from 4.86365 to 4.23622, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_4.236.h5\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 4.4567 - val_loss: 4.2362\n",
            "Epoch 12/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 4.2325\n",
            "Epoch 00012: val_loss improved from 4.23622 to 4.03858, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_4.039.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 4.2325 - val_loss: 4.0386\n",
            "Epoch 13/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 4.0564\n",
            "Epoch 00013: val_loss improved from 4.03858 to 3.75349, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_3.753.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 4.0564 - val_loss: 3.7535\n",
            "Epoch 14/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 3.9075\n",
            "Epoch 00014: val_loss improved from 3.75349 to 3.67257, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_3.673.h5\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 3.9075 - val_loss: 3.6726\n",
            "Epoch 15/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 3.7614\n",
            "Epoch 00015: val_loss did not improve from 3.67257\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 3.7614 - val_loss: 3.6791\n",
            "Epoch 16/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 3.6348\n",
            "Epoch 00016: val_loss improved from 3.67257 to 3.63290, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_3.633.h5\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 3.6348 - val_loss: 3.6329\n",
            "Epoch 17/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 3.5195\n",
            "Epoch 00017: val_loss improved from 3.63290 to 3.41982, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_3.420.h5\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 3.5195 - val_loss: 3.4198\n",
            "Epoch 18/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 3.4180\n",
            "Epoch 00018: val_loss improved from 3.41982 to 3.37111, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_3.371.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 3.4180 - val_loss: 3.3711\n",
            "Epoch 19/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 3.3263\n",
            "Epoch 00019: val_loss did not improve from 3.37111\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 3.3263 - val_loss: 3.3960\n",
            "Epoch 20/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 3.2266\n",
            "Epoch 00020: val_loss improved from 3.37111 to 3.27228, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_3.272.h5\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 3.2266 - val_loss: 3.2723\n",
            "Epoch 21/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 3.1485\n",
            "Epoch 00021: val_loss improved from 3.27228 to 3.13142, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_3.131.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 3.1485 - val_loss: 3.1314\n",
            "Epoch 22/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 3.0603\n",
            "Epoch 00022: val_loss did not improve from 3.13142\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 3.0603 - val_loss: 3.2358\n",
            "Epoch 23/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.9935\n",
            "Epoch 00023: val_loss did not improve from 3.13142\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 2.9935 - val_loss: 3.1718\n",
            "Epoch 24/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.9041\n",
            "Epoch 00024: val_loss improved from 3.13142 to 2.96742, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.967.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 2.9041 - val_loss: 2.9674\n",
            "Epoch 25/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.8436\n",
            "Epoch 00025: val_loss improved from 2.96742 to 2.86711, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.867.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 2.8436 - val_loss: 2.8671\n",
            "Epoch 26/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.7858\n",
            "Epoch 00026: val_loss did not improve from 2.86711\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 2.7858 - val_loss: 3.0078\n",
            "Epoch 27/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.7240\n",
            "Epoch 00027: val_loss did not improve from 2.86711\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 2.7240 - val_loss: 2.9858\n",
            "Epoch 28/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.6461\n",
            "Epoch 00028: val_loss improved from 2.86711 to 2.83598, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.836.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 2.6461 - val_loss: 2.8360\n",
            "Epoch 29/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.5854\n",
            "Epoch 00029: val_loss improved from 2.83598 to 2.78429, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.784.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 2.5854 - val_loss: 2.7843\n",
            "Epoch 30/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.5335\n",
            "Epoch 00030: val_loss improved from 2.78429 to 2.75223, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.752.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 2.5335 - val_loss: 2.7522\n",
            "Epoch 31/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.4731\n",
            "Epoch 00031: val_loss did not improve from 2.75223\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 2.4731 - val_loss: 2.7767\n",
            "Epoch 32/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.4351\n",
            "Epoch 00032: val_loss improved from 2.75223 to 2.71562, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.716.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 2.4351 - val_loss: 2.7156\n",
            "Epoch 33/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.3742\n",
            "Epoch 00033: val_loss did not improve from 2.71562\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 2.3742 - val_loss: 2.7422\n",
            "Epoch 34/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.3341\n",
            "Epoch 00034: val_loss improved from 2.71562 to 2.71526, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.715.h5\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 2.3341 - val_loss: 2.7153\n",
            "Epoch 35/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.2890\n",
            "Epoch 00035: val_loss did not improve from 2.71526\n",
            "288/288 [==============================] - 162s 564ms/step - loss: 2.2890 - val_loss: 2.7664\n",
            "Epoch 36/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.2290\n",
            "Epoch 00036: val_loss improved from 2.71526 to 2.70476, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.705.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 2.2290 - val_loss: 2.7048\n",
            "Epoch 37/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.1942\n",
            "Epoch 00037: val_loss improved from 2.70476 to 2.56546, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.565.h5\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 2.1942 - val_loss: 2.5655\n",
            "Epoch 38/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.1416\n",
            "Epoch 00038: val_loss improved from 2.56546 to 2.55026, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.550.h5\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 2.1416 - val_loss: 2.5503\n",
            "Epoch 39/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.1079\n",
            "Epoch 00039: val_loss improved from 2.55026 to 2.52562, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.526.h5\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 2.1079 - val_loss: 2.5256\n",
            "Epoch 40/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.0758\n",
            "Epoch 00040: val_loss improved from 2.52562 to 2.47187, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.472.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 2.0758 - val_loss: 2.4719\n",
            "Epoch 41/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 2.0270\n",
            "Epoch 00041: val_loss did not improve from 2.47187\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 2.0270 - val_loss: 2.5665\n",
            "Epoch 42/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.9944\n",
            "Epoch 00042: val_loss did not improve from 2.47187\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 1.9944 - val_loss: 2.4815\n",
            "Epoch 43/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.9589\n",
            "Epoch 00043: val_loss did not improve from 2.47187\n",
            "288/288 [==============================] - 163s 564ms/step - loss: 1.9589 - val_loss: 2.5357\n",
            "Epoch 44/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.9116\n",
            "Epoch 00044: val_loss did not improve from 2.47187\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 1.9116 - val_loss: 2.4994\n",
            "Epoch 45/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.8823\n",
            "Epoch 00045: val_loss improved from 2.47187 to 2.47166, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.472.h5\n",
            "288/288 [==============================] - 165s 571ms/step - loss: 1.8823 - val_loss: 2.4717\n",
            "Epoch 46/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.8566\n",
            "Epoch 00046: val_loss improved from 2.47166 to 2.42157, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.422.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.8566 - val_loss: 2.4216\n",
            "Epoch 47/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.8182\n",
            "Epoch 00047: val_loss did not improve from 2.42157\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.8182 - val_loss: 2.4366\n",
            "Epoch 48/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.7857\n",
            "Epoch 00048: val_loss did not improve from 2.42157\n",
            "288/288 [==============================] - 164s 568ms/step - loss: 1.7857 - val_loss: 2.4572\n",
            "Epoch 49/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.7553\n",
            "Epoch 00049: val_loss improved from 2.42157 to 2.37542, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.375.h5\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 1.7553 - val_loss: 2.3754\n",
            "Epoch 50/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.7148\n",
            "Epoch 00050: val_loss did not improve from 2.37542\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.7148 - val_loss: 2.3880\n",
            "Epoch 51/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.6927\n",
            "Epoch 00051: val_loss did not improve from 2.37542\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.6927 - val_loss: 2.4511\n",
            "Epoch 52/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.6595\n",
            "Epoch 00052: val_loss improved from 2.37542 to 2.33141, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.331.h5\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 1.6595 - val_loss: 2.3314\n",
            "Epoch 53/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.6329\n",
            "Epoch 00053: val_loss did not improve from 2.33141\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.6329 - val_loss: 2.3572\n",
            "Epoch 54/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.5983\n",
            "Epoch 00054: val_loss did not improve from 2.33141\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.5983 - val_loss: 2.3415\n",
            "Epoch 55/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.5793\n",
            "Epoch 00055: val_loss improved from 2.33141 to 2.32590, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.326.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.5793 - val_loss: 2.3259\n",
            "Epoch 56/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.5497\n",
            "Epoch 00056: val_loss improved from 2.32590 to 2.30561, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.306.h5\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 1.5497 - val_loss: 2.3056\n",
            "Epoch 57/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.5288\n",
            "Epoch 00057: val_loss did not improve from 2.30561\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.5288 - val_loss: 2.4432\n",
            "Epoch 58/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.5066\n",
            "Epoch 00058: val_loss did not improve from 2.30561\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 1.5066 - val_loss: 2.4059\n",
            "Epoch 59/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.4636\n",
            "Epoch 00059: val_loss did not improve from 2.30561\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 1.4636 - val_loss: 2.3941\n",
            "Epoch 60/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.4513\n",
            "Epoch 00060: val_loss did not improve from 2.30561\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 1.4513 - val_loss: 2.4835\n",
            "Epoch 61/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.4212\n",
            "Epoch 00061: val_loss did not improve from 2.30561\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 1.4212 - val_loss: 2.3555\n",
            "Epoch 62/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.3986\n",
            "Epoch 00062: val_loss did not improve from 2.30561\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.3986 - val_loss: 2.3083\n",
            "Epoch 63/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.3739\n",
            "Epoch 00063: val_loss did not improve from 2.30561\n",
            "288/288 [==============================] - 163s 564ms/step - loss: 1.3739 - val_loss: 2.3450\n",
            "Epoch 64/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.3651\n",
            "Epoch 00064: val_loss did not improve from 2.30561\n",
            "288/288 [==============================] - 163s 564ms/step - loss: 1.3651 - val_loss: 2.5604\n",
            "Epoch 65/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.3335\n",
            "Epoch 00065: val_loss improved from 2.30561 to 2.29939, saving model to /content/drive/My Drive/ocr_dataset/crnn_ocrtext_model8_updated_kfold1_2.299.h5\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.3335 - val_loss: 2.2994\n",
            "Epoch 66/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.3153\n",
            "Epoch 00066: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 1.3153 - val_loss: 2.5955\n",
            "Epoch 67/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.2949\n",
            "Epoch 00067: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 1.2949 - val_loss: 2.3430\n",
            "Epoch 68/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.2781\n",
            "Epoch 00068: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 1.2781 - val_loss: 2.3458\n",
            "Epoch 69/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.2426\n",
            "Epoch 00069: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 1.2426 - val_loss: 2.4096\n",
            "Epoch 70/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.2275\n",
            "Epoch 00070: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.2275 - val_loss: 2.4285\n",
            "Epoch 71/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.2107\n",
            "Epoch 00071: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.2107 - val_loss: 2.3463\n",
            "Epoch 72/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.1833\n",
            "Epoch 00072: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 1.1833 - val_loss: 2.2994\n",
            "Epoch 73/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.1733\n",
            "Epoch 00073: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 1.1733 - val_loss: 2.4002\n",
            "Epoch 74/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.1590\n",
            "Epoch 00074: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.1590 - val_loss: 2.4684\n",
            "Epoch 75/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.1339\n",
            "Epoch 00075: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 1.1339 - val_loss: 2.4285\n",
            "Epoch 76/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.1054\n",
            "Epoch 00076: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 1.1054 - val_loss: 2.3790\n",
            "Epoch 77/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.0915\n",
            "Epoch 00077: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 1.0915 - val_loss: 2.7128\n",
            "Epoch 78/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.0770\n",
            "Epoch 00078: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 568ms/step - loss: 1.0770 - val_loss: 2.4815\n",
            "Epoch 79/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.0727\n",
            "Epoch 00079: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 1.0727 - val_loss: 2.5459\n",
            "Epoch 80/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.0511\n",
            "Epoch 00080: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 566ms/step - loss: 1.0511 - val_loss: 2.4241\n",
            "Epoch 81/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.0306\n",
            "Epoch 00081: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 568ms/step - loss: 1.0306 - val_loss: 2.3995\n",
            "Epoch 82/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 1.0017\n",
            "Epoch 00082: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 1.0017 - val_loss: 2.4105\n",
            "Epoch 83/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.9994\n",
            "Epoch 00083: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 0.9994 - val_loss: 2.4575\n",
            "Epoch 84/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.9792\n",
            "Epoch 00084: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 0.9792 - val_loss: 2.4479\n",
            "Epoch 85/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.9585\n",
            "Epoch 00085: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 0.9585 - val_loss: 2.4270\n",
            "Epoch 86/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.9451\n",
            "Epoch 00086: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 0.9451 - val_loss: 2.5053\n",
            "Epoch 87/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.9472\n",
            "Epoch 00087: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 0.9472 - val_loss: 2.5199\n",
            "Epoch 88/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.9175\n",
            "Epoch 00088: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 0.9175 - val_loss: 2.6977\n",
            "Epoch 89/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.9017\n",
            "Epoch 00089: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 567ms/step - loss: 0.9017 - val_loss: 2.4085\n",
            "Epoch 90/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.8825\n",
            "Epoch 00090: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 564ms/step - loss: 0.8825 - val_loss: 2.4655\n",
            "Epoch 91/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.8852\n",
            "Epoch 00091: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 0.8852 - val_loss: 2.4595\n",
            "Epoch 92/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.8695\n",
            "Epoch 00092: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 564ms/step - loss: 0.8695 - val_loss: 2.6208\n",
            "Epoch 93/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.8582\n",
            "Epoch 00093: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 565ms/step - loss: 0.8582 - val_loss: 2.5223\n",
            "Epoch 94/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.8288\n",
            "Epoch 00094: val_loss did not improve from 2.29939\n",
            "288/288 [==============================] - 163s 564ms/step - loss: 0.8288 - val_loss: 2.5940\n",
            "Epoch 95/300\n",
            "288/288 [==============================] - ETA: 0s - loss: 0.8192"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-4569f5ed7b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m         model_final.fit(x=[tx, train_y, train_input_len, train_label_len], y=train_output, \n\u001b[1;32m     61\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtesx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_input_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_label_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMC\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                         epochs=300, batch_size=128)\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5bkE69fhsHd"
      },
      "source": [
        "\n",
        "filepath = \"/content/drive/My Drive/ocr_dataset/crnn_ocrtext_model7_updated_kfold\" + str(countxx) + \"_{val_loss:.3f}.h5\"\n",
        "\n",
        "# del imgset\n",
        "\n",
        "MC = keras.callbacks.ModelCheckpoint(\n",
        "    filepath,\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"auto\",\n",
        "    save_freq=\"epoch\",\n",
        ")\n",
        "\n",
        "model_final.fit(x=[tx, train_y, train_input_len, train_label_len], y=train_output, \n",
        "                validation_data=([tesx, valid_y, valid_input_len, valid_label_len], valid_output),callbacks=[MC],\n",
        "                epochs=300, batch_size=128)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYrPN8Wmkjwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbbf49be-6c15-4123-da06-7e03e1de14cf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11., 20.,  2., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJdey7EoF6f9"
      },
      "source": [
        "filepath = \"/content/crnn_ocrtext_model_updated_{val_loss:.2f}.h5\"\n",
        "\n",
        "\n",
        "MC = keras.callbacks.ModelCheckpoint(\n",
        "    filepath,\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"auto\",\n",
        "    save_freq=\"epoch\",\n",
        ")\n",
        "\n",
        "model_final.fit(x=[imgs[:30000], train_y, train_input_len, train_label_len], y=train_output, \n",
        "                validation_data=([imgs[30000:35000], valid_y, valid_input_len, valid_label_len], valid_output),callbacks=[MC],\n",
        "                epochs=200, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viMrXCEs_sUe"
      },
      "source": [
        "# !cp \"/content/crnn_ocrtext_model_updated_1.90.h5\" \"/content/drive/My Drive/ocr_dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8kLQaOHbjhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366aa66b-27fc-420d-f2a3-3df36d452db6"
      },
      "source": [
        "ca = glob(\"*kfold*\")\n",
        "ca[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['crnn_ocrtext_model_updated_kfold8_0.706.h5',\n",
              " 'crnn_ocrtext_model_updated_kfold2_2.997.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tndh0FuAb1fX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-JhVrf2bjsh"
      },
      "source": [
        "for c in ca[:]:\n",
        "    !cp {c} \"/content/drive/My Drive/ocr_dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktYLzCepwSB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59005195-484d-4a5a-b9f6-6db076919ed7"
      },
      "source": [
        "!cp  \"/content/drive/My Drive/ocr_dataset/crnn_ocrtext_model_updated_kfold4_1.480.h5\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/drive/My Drive/ocr_dataset/crnn_ocrtext_model_updated_kfold4_1.480.h5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzAYLRzJv7bP"
      },
      "source": [
        "model.load_weights(\"/content/crnn_ocrtext_model_updated_kfold5_1.132.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DkwsY6hmJVX"
      },
      "source": [
        "\n",
        "for i in range(len(train_y)):\n",
        "    if sum(train_y[i])<-24:\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8FLOjKglMWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d653a3-2964-428c-d05e-f701fab7e690"
      },
      "source": [
        "\n",
        "for i in range(len(valid_y)):\n",
        "    if sum(valid_y[i])<-24:\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb1aVyF6lzns"
      },
      "source": [
        "string = tesy[357]\n",
        "valid_label_len[i] = len(string)\n",
        "valid_y[i, 0:len(string)]= label_to_num(string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygnZd55Ql5Pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a5ee59-0281-499d-b3b1-6717cb8b9cf9"
      },
      "source": [
        "label_to_num(\"abc\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1, -1, -1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keGZ5EE4ldLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06fd1b2a-e4e0-4985-d528-0cad5b375e9c"
      },
      "source": [
        "valid_y[357]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4aqoZ-ukpP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7aa3663-b13a-4720-cebc-81e755760a64"
      },
      "source": [
        "ty[357]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'JERINECK'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj9TvDLXczkK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjycOAI6czsv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n84Ab5rLmjvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3776386-367a-4102-fc89-8d22aac6d0da"
      },
      "source": [
        "preds = model.predict(tesx)\n",
        "decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n",
        "                                   greedy=True)[0][0])\n",
        "\n",
        "prediction = []\n",
        "for i in range(len(preds)):\n",
        "    prediction.append(num_to_label(decoded[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_uKdf0ZhMox"
      },
      "source": [
        "y_true = tesy\n",
        "correct_char = 0\n",
        "total_char = 0\n",
        "correct = 0\n",
        "symbol_ = 0\n",
        "sym_ = 0\n",
        "\n",
        "for i in range(len(preds)):\n",
        "    pr = prediction[i]\n",
        "    tr = y_true[i]\n",
        "    total_char += len(tr)\n",
        "    \n",
        "    for j in range(min(len(tr), len(pr))):\n",
        "        if tr[j] == pr[j]:\n",
        "            correct_char += 1\n",
        "    if \" \" in pr:\n",
        "        symbol_ +=1\n",
        "    if \"'\" in pr or \"-\" in pr:\n",
        "        sym_ += 1\n",
        "    if pr == tr :\n",
        "        correct += 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QA9lQ8f1cLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac2cd8b-a40c-4ee3-bc75-d03af8c8ebd0"
      },
      "source": [
        "\n",
        "print('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\n",
        "print('Correct words predicted      : %.2f%%' %(correct*100/val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct characters predicted : 94.88%\n",
            "Correct words predicted      : 87.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZIhUIjJ6tbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a026fb31-17fa-4ef3-c334-31f0bb54027a"
      },
      "source": [
        "sym_,symbol_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP4-dGn4RSmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d9f15b-17c3-4db0-8810-72849fb083e6"
      },
      "source": [
        "imgs[999].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(280, 45, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEnYdq_tRV6R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "c842565c-1277-49ca-82d6-30537b860fc1"
      },
      "source": [
        "cv2_imshow(imgs[5]*255)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=280x45 at 0x7F7637AF1AC8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kieag-vKRIVO"
      },
      "source": [
        "cv2_imshow(imgs[999])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR2g3Mb5P4_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aada0134-a401-4d5d-f2db-3390062d7b25"
      },
      "source": [
        "pr,tr,i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('MARIE-STELLA', 'MARIESTELLA', 999)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyPwtigZcrbi"
      },
      "source": [
        "### check performance over 100-100 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3FtUjno1pu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042da5a7-64a0-4484-958e-d4edb7c38891"
      },
      "source": [
        "correct_char = 0\n",
        "total_char = 0\n",
        "correct = 0\n",
        "symbol_ = 0\n",
        "sym_ = 0\n",
        "for ran in range(0,len(preds),100):\n",
        "    correct_char = 0\n",
        "    total_char = 0\n",
        "    correct = 0\n",
        "    symbol_ = 0\n",
        "    sym_ = 0\n",
        "    for i in range(ran,min(len(preds),ran+100)):\n",
        "        pr = prediction[i]\n",
        "        tr = y_true[i]\n",
        "        total_char += len(tr)\n",
        "        \n",
        "        for j in range(min(len(tr), len(pr))):\n",
        "            if tr[j] == pr[j]:\n",
        "                correct_char += 1\n",
        "        # print(\"Actual:- \",tr,\"    <--->    Predicted:- \",pr )\n",
        "        if \" \" in pr:\n",
        "            symbol_ +=1\n",
        "        if \"'\" in pr or \"-\" in pr:\n",
        "            sym_ += 1\n",
        "        if pr == tr :\n",
        "            correct += 1 \n",
        "    print(\"range:-\",ran,\"-\",ran+100, \"correct:-\",correct,\"%\",\"   char\" ,correct_char*100/total_char,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range:- 0 - 100 correct:- 80 %    char 93.24116743471582 %\n",
            "range:- 100 - 200 correct:- 86 %    char 94.21613394216133 %\n",
            "range:- 200 - 300 correct:- 93 %    char 96.92307692307692 %\n",
            "range:- 300 - 400 correct:- 88 %    char 92.9676511954993 %\n",
            "range:- 400 - 500 correct:- 90 %    char 96.46869983948636 %\n",
            "range:- 500 - 600 correct:- 89 %    char 94.90445859872611 %\n",
            "range:- 600 - 700 correct:- 90 %    char 95.84615384615384 %\n",
            "range:- 700 - 800 correct:- 84 %    char 93.23899371069183 %\n",
            "range:- 800 - 900 correct:- 89 %    char 95.49549549549549 %\n",
            "range:- 900 - 1000 correct:- 83 %    char 94.5266272189349 %\n",
            "range:- 1000 - 1100 correct:- 86 %    char 96.09609609609609 %\n",
            "range:- 1100 - 1200 correct:- 91 %    char 97.06314243759178 %\n",
            "range:- 1200 - 1300 correct:- 86 %    char 90.07751937984496 %\n",
            "range:- 1300 - 1400 correct:- 86 %    char 92.06106870229007 %\n",
            "range:- 1400 - 1500 correct:- 83 %    char 90.8675799086758 %\n",
            "range:- 1500 - 1600 correct:- 88 %    char 95.46165884194053 %\n",
            "range:- 1600 - 1700 correct:- 92 %    char 94.16282642089094 %\n",
            "range:- 1700 - 1800 correct:- 92 %    char 96.54088050314465 %\n",
            "range:- 1800 - 1900 correct:- 85 %    char 93.77916018662519 %\n",
            "range:- 1900 - 2000 correct:- 92 %    char 96.71641791044776 %\n",
            "range:- 2000 - 2100 correct:- 91 %    char 95.41984732824427 %\n",
            "range:- 2100 - 2200 correct:- 84 %    char 95.03105590062111 %\n",
            "range:- 2200 - 2300 correct:- 85 %    char 94.0387481371088 %\n",
            "range:- 2300 - 2400 correct:- 83 %    char 93.94904458598727 %\n",
            "range:- 2400 - 2500 correct:- 91 %    char 94.38700147710487 %\n",
            "range:- 2500 - 2600 correct:- 89 %    char 96.77938808373591 %\n",
            "range:- 2600 - 2700 correct:- 88 %    char 96.11650485436893 %\n",
            "range:- 2700 - 2800 correct:- 84 %    char 95.7957957957958 %\n",
            "range:- 2800 - 2900 correct:- 92 %    char 96.43962848297214 %\n",
            "range:- 2900 - 3000 correct:- 89 %    char 95.48286604361371 %\n",
            "range:- 3000 - 3100 correct:- 90 %    char 96.06656580937972 %\n",
            "range:- 3100 - 3200 correct:- 85 %    char 93.89312977099236 %\n",
            "range:- 3200 - 3300 correct:- 87 %    char 92.80469897209986 %\n",
            "range:- 3300 - 3400 correct:- 91 %    char 95.3560371517028 %\n",
            "range:- 3400 - 3500 correct:- 94 %    char 97.06336939721793 %\n",
            "range:- 3500 - 3600 correct:- 89 %    char 97.46434231378764 %\n",
            "range:- 3600 - 3700 correct:- 84 %    char 95.37037037037037 %\n",
            "range:- 3700 - 3800 correct:- 93 %    char 95.73820395738204 %\n",
            "range:- 3800 - 3900 correct:- 87 %    char 94.0 %\n",
            "range:- 3900 - 4000 correct:- 89 %    char 93.89067524115755 %\n",
            "range:- 4000 - 4100 correct:- 95 %    char 99.07120743034056 %\n",
            "range:- 4100 - 4200 correct:- 89 %    char 95.0 %\n",
            "range:- 4200 - 4300 correct:- 86 %    char 95.73170731707317 %\n",
            "range:- 4300 - 4400 correct:- 92 %    char 97.6 %\n",
            "range:- 4400 - 4500 correct:- 89 %    char 96.14147909967846 %\n",
            "range:- 4500 - 4600 correct:- 84 %    char 94.33384379785605 %\n",
            "range:- 4600 - 4700 correct:- 85 %    char 92.8902627511592 %\n",
            "range:- 4700 - 4800 correct:- 88 %    char 93.37175792507205 %\n",
            "range:- 4800 - 4900 correct:- 88 %    char 94.91017964071857 %\n",
            "range:- 4900 - 5000 correct:- 92 %    char 98.54014598540147 %\n",
            "range:- 5000 - 5100 correct:- 83 %    char 93.32321699544765 %\n",
            "range:- 5100 - 5200 correct:- 86 %    char 93.75951293759513 %\n",
            "range:- 5200 - 5300 correct:- 91 %    char 97.91976225854383 %\n",
            "range:- 5300 - 5400 correct:- 82 %    char 94.6319018404908 %\n",
            "range:- 5400 - 5500 correct:- 86 %    char 94.48818897637796 %\n",
            "range:- 5500 - 5600 correct:- 92 %    char 96.10194902548726 %\n",
            "range:- 5600 - 5700 correct:- 85 %    char 94.76923076923077 %\n",
            "range:- 5700 - 5800 correct:- 87 %    char 92.28571428571429 %\n",
            "range:- 5800 - 5900 correct:- 85 %    char 93.17507418397626 %\n",
            "range:- 5900 - 6000 correct:- 88 %    char 94.45300462249615 %\n",
            "range:- 6000 - 6100 correct:- 86 %    char 93.51432880844645 %\n",
            "range:- 6100 - 6200 correct:- 92 %    char 97.08029197080292 %\n",
            "range:- 6200 - 6300 correct:- 93 %    char 98.31029185867895 %\n",
            "range:- 6300 - 6400 correct:- 82 %    char 92.21556886227545 %\n",
            "range:- 6400 - 6500 correct:- 94 %    char 96.55712050078247 %\n",
            "range:- 6500 - 6600 correct:- 84 %    char 90.77598828696925 %\n",
            "range:- 6600 - 6700 correct:- 83 %    char 91.2781954887218 %\n",
            "range:- 6700 - 6800 correct:- 92 %    char 94.12673879443585 %\n",
            "range:- 6800 - 6900 correct:- 87 %    char 95.70747217806041 %\n",
            "range:- 6900 - 7000 correct:- 89 %    char 96.50986342943854 %\n",
            "range:- 7000 - 7100 correct:- 88 %    char 94.45255474452554 %\n",
            "range:- 7100 - 7200 correct:- 84 %    char 92.95558958652374 %\n",
            "range:- 7200 - 7300 correct:- 90 %    char 95.96122778675283 %\n",
            "range:- 7300 - 7400 correct:- 89 %    char 96.6824644549763 %\n",
            "range:- 7400 - 7500 correct:- 83 %    char 94.72868217054264 %\n",
            "range:- 7500 - 7600 correct:- 86 %    char 94.44444444444444 %\n",
            "range:- 7600 - 7700 correct:- 88 %    char 92.04368174726989 %\n",
            "range:- 7700 - 7800 correct:- 90 %    char 97.08141321044546 %\n",
            "range:- 7800 - 7900 correct:- 90 %    char 95.26627218934911 %\n",
            "range:- 7900 - 8000 correct:- 88 %    char 96.17083946980854 %\n",
            "range:- 8000 - 8100 correct:- 90 %    char 97.92899408284023 %\n",
            "range:- 8100 - 8200 correct:- 85 %    char 93.57664233576642 %\n",
            "range:- 8200 - 8300 correct:- 60 %    char 88.8268156424581 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGjlcPCT9RmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2afd807b-91c2-4eda-c0d8-2d1d6c2abbd8"
      },
      "source": [
        "for j in range(0,350,100):\n",
        "    print(j)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ftJUhso7Ke6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed57161-6342-47c7-8e33-bb93b4d55c9d"
      },
      "source": [
        "\n",
        "print('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\n",
        "print('Correct words predicted      : %.2f%%' %(correct*100/100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct characters predicted : 94.94%\n",
            "Correct words predicted      : 85.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6EJZ5x6dccN"
      },
      "source": [
        "### pred on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ROaFMbb7X7W"
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "test_path = glob(\"TEST/*\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4F2a4fvx_nv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c687e25-02a4-4954-bd69-39e9d4936d70"
      },
      "source": [
        "test_path.sort()\n",
        "test_path[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TEST/000000.jpg', 'TEST/000001.jpg', 'TEST/000002.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e70cI6cn-adq"
      },
      "source": [
        "\n",
        "imgs    = [savePaddedImg(load_rethink_image( cv2.imread(q, cv2.IMREAD_GRAYSCALE))) for q in test_path ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEXTna9C-oS3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5M3OlKb-rSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a1ab12-8326-4739-a469-86684f723a5f"
      },
      "source": [
        "test_path[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TEST/013123.jpg', 'TEST/000583.jpg', 'TEST/005374.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB8YApV9_iZe"
      },
      "source": [
        "imgs = np.array(imgs).reshape(-1, 45, 280, 1)\n",
        "# valid_x = np.array(valid_x).reshape(-1, 256, 64, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFoGV0LExHh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08375b86-621d-4a92-807d-edc97cba088b"
      },
      "source": [
        "imgs[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 280, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2WZbysLc3KV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rflfQJN-6MI"
      },
      "source": [
        "\n",
        "pred_val = model.predict(imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC2lar8-_dGF"
      },
      "source": [
        "decoded = K.get_value(K.ctc_decode(pred_val, input_length=np.ones(pred_val.shape[0])*pred_val.shape[1], \n",
        "                                   greedy=True)[0][0])\n",
        "prediction = []\n",
        "for i in range(len(pred_val)):\n",
        "    prediction.append(num_to_label(decoded[i]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Stz09m5xjxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0067c3-91f9-47b5-92de-b54acce06482"
      },
      "source": [
        "prediction[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CASSANDRE', 'PETAUX', 'BONNIN', 'TANQUEREL', 'COZE']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj-AnW2Nxla-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "b61b7fe1-87d9-4575-81ef-c9a0b6f1d2ad"
      },
      "source": [
        "[cv2_imshow( cv2.imread(q, cv2.IMREAD_GRAYSCALE)) for q in test_path[:5] ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=388x20 at 0x7FE8D1D3C4A8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=284x31 at 0x7FE8D1D3C5C0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=324x44 at 0x7FE8D1D3C4A8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=284x31 at 0x7FE8D1D3C5C0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=284x50 at 0x7FE8D1D3C4A8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUQEvqbNyVmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63b7f4b-8d3a-4a16-bef0-8a9b5a8458fc"
      },
      "source": [
        "test_path[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TEST/000000.jpg', 'TEST/000001.jpg', 'TEST/000002.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xTDNztTxpwR"
      },
      "source": [
        "pred_dict = {}\n",
        "for index in range(len(test_path)):\n",
        "    fname = test_path[index].split(\"/\")[-1]\n",
        "    pred_dict[fname] = prediction[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1r_MaFryuOg"
      },
      "source": [
        "pd.Series(pred_dict).to_csv(\"res_test1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMVRdN7Eyvd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f1ab938-8524-424b-f9e7-aecebbd5a15f"
      },
      "source": [
        "# identifying single character prediction which in generally do not appear in image\n",
        "for i in range(len(prediction)):\n",
        "    string = prediction[i]\n",
        "    if len(string) <2:\n",
        "        print(i,\" \",string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "463   M\n",
            "2342   \n",
            "2372   E\n",
            "3497   V\n",
            "4704   A\n",
            "6605   P\n",
            "6952   E\n",
            "8050   E\n",
            "8643   E\n",
            "8953   E\n",
            "9014   E\n",
            "9828   M\n",
            "10162   M\n",
            "10163   M\n",
            "11206   E\n",
            "11580   M\n",
            "12119   E\n",
            "12899   E\n",
            "14230   J\n",
            "15163   A\n",
            "15815   T\n",
            "16160   T\n",
            "16282   \n",
            "16877   E\n",
            "17457   E\n",
            "18098   E\n",
            "18737   U\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGtfAFn_04xI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "715b126a-783f-4507-c288-8944a50d12e4"
      },
      "source": [
        "# identifying blank images\n",
        "dt = pd.read_csv(\"TRAIN.csv\")\n",
        "# df.head()\n",
        "\n",
        "dt[dt.VALUES.isna()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FILENAME</th>\n",
              "      <th>VALUES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>000039.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>000415.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3551</th>\n",
              "      <td>003551.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3555</th>\n",
              "      <td>003555.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3730</th>\n",
              "      <td>003730.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161658</th>\n",
              "      <td>161658.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161918</th>\n",
              "      <td>161918.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162151</th>\n",
              "      <td>162151.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164285</th>\n",
              "      <td>164285.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165176</th>\n",
              "      <td>165176.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>272 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          FILENAME VALUES\n",
              "39      000039.jpg    NaN\n",
              "415     000415.jpg    NaN\n",
              "3551    003551.jpg    NaN\n",
              "3555    003555.jpg    NaN\n",
              "3730    003730.jpg    NaN\n",
              "...            ...    ...\n",
              "161658  161658.jpg    NaN\n",
              "161918  161918.jpg    NaN\n",
              "162151  162151.jpg    NaN\n",
              "164285  164285.jpg    NaN\n",
              "165176  165176.jpg    NaN\n",
              "\n",
              "[272 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue0XofGcgRN6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWy43KgSccf1"
      },
      "source": [
        "### direct load and predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIOm21jxgRRz"
      },
      "source": [
        "model.load_weights(\"/content/crnn_ocrtext_model_updated_kfold8_0.706.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbqsmru71WG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef350fa-9d68-4680-cb57-d4c75a6d4a32"
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "test_path = glob(\"TEST/*\")\n",
        "\n",
        "test_path.sort()\n",
        "test_path[:3]\n",
        "\n",
        "\n",
        "imgs    = [savePaddedImg(load_rethink_image( cv2.imread(q, cv2.IMREAD_GRAYSCALE))) for q in test_path ]\n",
        "\n",
        "imgs = np.array(imgs).reshape(-1, 45, 280, 1)\n",
        "pred_val = model.predict(imgs)\n",
        "decoded = K.get_value(K.ctc_decode(pred_val, input_length=np.ones(pred_val.shape[0])*pred_val.shape[1], \n",
        "                                   greedy=True)[0][0])\n",
        "prediction = []\n",
        "for i in range(len(pred_val)):\n",
        "    prediction.append(num_to_label(decoded[i]))\n",
        "\n",
        "\n",
        "pred_dict = {}\n",
        "for index in range(len(test_path)):\n",
        "    fname = test_path[index].split(\"/\")[-1]\n",
        "    pred_dict[fname] = prediction[index]\n",
        "\n",
        "pd.Series(pred_dict).to_csv(\"res_test0_0629.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NHbTieTdjIO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}