Usenet is of a set of 20,000 messages sent to 20 Usenet bulletin boards in 1993.
In this dataset include newsgroups for topics like politics, religion, cars, sports, and cryptography.
Offer a rich set of text written by many users and this will involve Pre-Processing.



Topic involved in analysis of Usenet messages
- Pre-Processing
- tf-idf
- Topic Modeling(using LDA)
- Sentiment Analysis 
	- by Word
	- by Message
	- by 2-gram 


My next planing is to incorporation of WordVectors so we can similar words as we are highly depended on exact word 
other simple tokenization technique like stemming and lemmatization could be involved.
I have not used as after that it will hard to interpret most words. 